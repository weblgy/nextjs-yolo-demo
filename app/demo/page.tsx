"use client";

import { useState, useRef, useEffect } from "react";
import * as ort from "onnxruntime-web";
import { Button } from "@/components/ui/button";
import { Card, CardContent } from "@/components/ui/card";
import { preprocess, renderBoxes } from "@/lib/utils";
import {
    Camera, StopCircle, Play, ImageIcon, Loader2,
    Maximize2, Minimize2, // <--- æ–°å¢è¿™ä¸¤ä¸ªå›¾æ ‡
    Zap,
    Upload
} from "lucide-react";

// --- 1. å…¨å±€é…ç½® ONNX Runtime ---
// æŒ‡å®š WASM æ–‡ä»¶ä½äº public æ ¹ç›®å½•
ort.env.wasm.wasmPaths = "/";
// ç¦ç”¨å¤šçº¿ç¨‹ï¼Œé˜²æ­¢å¼€å‘ç¯å¢ƒå‡ºç° SharedArrayBuffer é”™è¯¯
// @ts-ignore
ort.env.wasm.numThreads = 1;

export default function DemoPage() {
    // --- çŠ¶æ€ç®¡ç† ---
    const [model, setModel] = useState<ort.InferenceSession | null>(null); // æ¨¡å‹ Session
    const [imageSrc, setImageSrc] = useState<string | null>(null);         // é™æ€å›¾ç‰‡è·¯å¾„
    const [loading, setLoading] = useState(false);                         // æ¨ç†åŠ è½½çŠ¶æ€
    const [inferenceTime, setInferenceTime] = useState<number | null>(null); // æ¨ç†è€—æ—¶
    const [isWebcamOpen, setIsWebcamOpen] = useState(false);               // æ‘„åƒå¤´å¼€å…³çŠ¶æ€

    // --- Refs ---
    const canvasRef = useRef<HTMLCanvasElement>(null);
    const videoRef = useRef<HTMLVideoElement>(null);
    const requestRef = useRef<number>(0); // ç”¨äºå–æ¶ˆ requestAnimationFrame
    const fileInputRef = useRef<HTMLInputElement>(null);
    const videoInputRef = useRef<HTMLInputElement>(null);
    // åœ¨ç»„ä»¶å†…éƒ¨å¢åŠ ä¸€ä¸ª Ref ç”¨æ¥åšâ€œé”â€ï¼Œé˜²æ­¢æ¨ç†ä»»åŠ¡å †ç§¯
    const isProcessingRef = useRef(false);
    const lastTimeRef = useRef(0);
    const frameCountRef = useRef(0); // ç”¨æ¥é™ä½ UI åˆ·æ–°é¢‘ç‡
    const containerRef = useRef<HTMLDivElement>(null); // <--- æ–°å¢è¿™ä¸ª ref
    const [isFullscreen, setIsFullscreen] = useState(false); // <--- è®°å½•å…¨å±çŠ¶æ€

    // --- 2. åˆå§‹åŒ–åŠ è½½æ¨¡å‹ ---
    useEffect(() => {
        const initModel = async () => {
            try {
                // âš ï¸ ç¡®ä¿ä½ çš„ public/model/ æ–‡ä»¶å¤¹ä¸‹æœ‰è¿™ä¸ªæ–‡ä»¶
                // å¦‚æœä½ ç”¨çš„æ˜¯ yolov8nï¼Œè¯·æ”¹æˆ "yolov8n.onnx"
                const modelPath = "/model/yolo11s.onnx";

                const session = await ort.InferenceSession.create(modelPath, {
                    executionProviders: ["wasm"],
                });
                setModel(session);
                console.log("æ¨¡å‹åŠ è½½æˆåŠŸ!");
            } catch (e) {
                console.error("æ¨¡å‹åŠ è½½å¤±è´¥:", e);
                alert("æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ§åˆ¶å°æŠ¥é”™ (é€šå¸¸æ˜¯è·¯å¾„æˆ–æ–‡ä»¶ç¼ºå¤±)");
            }
        };
        initModel();
    }, []);

    // --- 3. é™æ€å›¾ç‰‡æ¨ç†é€»è¾‘ (å·²ä¿®å¤å›¾ç‰‡æ¶ˆå¤±é—®é¢˜) ---
    const runInference = async () => {
        if (!model || !imageSrc || !canvasRef.current) return;
        if (isWebcamOpen) stopWebcam();

        setLoading(true);
        const start = performance.now();

        try {
            const img = new Image();
            img.src = imageSrc;
            await new Promise((resolve) => (img.onload = resolve));

            const canvas = canvasRef.current;
            const ctx = canvas.getContext("2d");

            // 1. åŒæ­¥å°ºå¯¸
            canvas.width = img.naturalWidth;
            canvas.height = img.naturalHeight;

            // âš ï¸ åˆ é™¤è¿™ä¸¤è¡Œï¼šä¸è¦åœ¨ Canvas ä¸Šç”»åŸå›¾ï¼Œåªç”»æ¡†ï¼
            // if (ctx) {
            //     ctx.drawImage(img, 0, 0); 
            // }

            // ç¡®ä¿æ¸…ç©ºä¹‹å‰çš„æ¡†
            ctx?.clearRect(0, 0, canvas.width, canvas.height);

            // 2. é¢„å¤„ç† & æ¨ç†
            const inputTensorData = await preprocess(img, 640, 640);
            const inputTensor = new ort.Tensor("float32", Float32Array.from(inputTensorData), [1, 3, 640, 640]);

            const outputs = await model.run({ images: inputTensor });
            const output = outputs["output0"];

            const end = performance.now();
            setInferenceTime(end - start);

            // 3. ç»˜åˆ¶ç»“æœ
            renderBoxes(canvas, 0.25, output.data as Float32Array, 0, 0);

        } catch (e) {
            console.error(e);
            alert("æ¨ç†å‡ºé”™ï¼Œè¯·æ£€æŸ¥æ§åˆ¶å°");
        } finally {
            setLoading(false);
        }
    };

    // --- 4. æ‘„åƒå¤´å¤„ç†é€»è¾‘ ---

    const startWebcam = async () => {
        // å¦‚æœå·²ç»å¼€å¯ï¼Œç‚¹å‡»æŒ‰é’®åˆ™å…³é—­
        if (isWebcamOpen) {
            stopWebcam();
            return;
        }

        // ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šå¼€å¯æ‘„åƒå¤´å‰ï¼Œæ¸…ç©ºé™æ€å›¾ç‰‡
        setImageSrc(null);
        setInferenceTime(null);

        try {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: {
                    // facingMode: "environment", // ä¼˜å…ˆä½¿ç”¨åç½®æ‘„åƒå¤´
                    width: { ideal: 640 },
                    height: { ideal: 480 }     // é€‚å½“é™ä½åˆ†è¾¨ç‡ä»¥æé«˜ FPS
                },
                audio: false,
            });

            if (videoRef.current) {
                videoRef.current.srcObject = stream;
                videoRef.current.onloadedmetadata = () => {
                    videoRef.current?.play();
                    setIsWebcamOpen(true);
                    detectFrame(); // å¼€å§‹å¾ªç¯æ£€æµ‹
                };
            }
        } catch (err) {
            console.error("æ‘„åƒå¤´å¯åŠ¨å¤±è´¥:", err);
            alert("æ— æ³•è®¿é—®æ‘„åƒå¤´ï¼Œè¯·æ£€æŸ¥æƒé™ã€‚");
        }
    };

    const stopWebcam = () => {
        // 1. åœæ­¢ AI å¾ªç¯
        if (requestRef.current) {
            cancelAnimationFrame(requestRef.current);
            requestRef.current = undefined;
        }

        if (videoRef.current) {
            const video = videoRef.current;

            // ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šå…ˆè§£é™¤ç›‘å¬ï¼Œé˜²æ­¢æ¸…ç©º src æ—¶è§¦å‘æŠ¥é”™å¼¹çª— ğŸ”¥
            video.onerror = null;
            video.onloadeddata = null;

            // 2. åœæ­¢æ’­æ”¾å¹¶æ¸…ç©º
            if (video.srcObject) {
                // å¦‚æœæ˜¯æ‘„åƒå¤´
                const stream = video.srcObject as MediaStream;
                stream.getTracks().forEach(track => track.stop());
                video.srcObject = null;
            } else {
                // å¦‚æœæ˜¯è§†é¢‘æ–‡ä»¶
                video.pause();
                video.src = "";
                video.load();
            }
        }

        // 3. æ¸…ç†ç”»å¸ƒ
        if (canvasRef.current) {
            const ctx = canvasRef.current.getContext("2d");
            // æ¸…ç©ºç”»å¸ƒï¼Œé˜²æ­¢ç»¿æ¡†æ®‹ç•™
            ctx?.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);
        }

        // 4. é‡ç½®çŠ¶æ€
        setIsWebcamOpen(false);
        setLoading(false);

        // 5. é€€å‡ºå…¨å±
        if (document.fullscreenElement) {
            document.exitFullscreen().catch(() => { });
        }
    };

    // --- ä¿®æ”¹åçš„æ£€æµ‹å¾ªç¯ ---
    const detectFrame = async () => {
        if (!videoRef.current || !canvasRef.current || !model) return;

        const video = videoRef.current;
        const canvas = canvasRef.current;
        const ctx = canvas.getContext("2d");

        if (video.readyState === 4 && !video.paused && !video.ended) {
            // 1. åŒæ­¥å°ºå¯¸
            if (canvas.width !== video.videoWidth || canvas.height !== video.videoHeight) {
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
            }

            // --- âš¡ï¸ æ ¸å¿ƒä¼˜åŒ–ï¼šä¸»åŠ¨èŠ‚æµ (Throttling) ---
            const now = Date.now();
            // é™åˆ¶è‡³å°‘é—´éš” 80ms (çº¦ 12 FPS)ï¼Œè¿™æ˜¯ Web ç«¯å®æ—¶æ£€æµ‹çš„é»„é‡‘å¹³è¡¡ç‚¹
            if (now - lastTimeRef.current >= 80 && !isProcessingRef.current) {

                isProcessingRef.current = true;
                lastTimeRef.current = now; // æ›´æ–°æ—¶é—´æˆ³

                try {
                    const start = performance.now();

                    // é¢„å¤„ç† & æ¨ç†
                    const inputTensorData = await preprocess(video, 640, 640);
                    const inputTensor = new ort.Tensor("float32", Float32Array.from(inputTensorData), [1, 3, 640, 640]);
                    const outputs = await model.run({ images: inputTensor });
                    const output = outputs["output0"];

                    const end = performance.now();

                    // --- ä¼˜åŒ– UI æ›´æ–°é¢‘ç‡ ---
                    // åªæœ‰æ¯ 5 å¸§æ‰æ›´æ–°ä¸€æ¬¡è€—æ—¶æ˜¾ç¤ºï¼Œå‡å°‘ React é‡ç»˜å‹åŠ›
                    frameCountRef.current++;
                    if (frameCountRef.current % 5 === 0) {
                        setInferenceTime(end - start);
                    }

                    // 2. ç»˜åˆ¶å‰æ¸…ç©ºç”»å¸ƒ (æ¸…é™¤ä¸Šä¸€å¸§çš„æ¡†)
                    ctx?.clearRect(0, 0, canvas.width, canvas.height);

                    // 3. ç»˜åˆ¶æ–°æ¡† (ä½¿ç”¨ä¿®å¤åçš„ utils)
                    renderBoxes(canvas, 0.25, output.data as Float32Array, 0, 0);

                } catch (e) {
                    console.error("æ¨ç†æŠ¥é”™:", e);
                } finally {
                    isProcessingRef.current = false;
                }
            }
        }

        // ä¾ç„¶ä¿æŒå…¨é€Ÿå¾ªç¯ï¼Œä½† AI åªæœ‰åœ¨æ»¡è¶³æ—¶é—´é—´éš”æ—¶æ‰è¿è¡Œ
        requestRef.current = requestAnimationFrame(detectFrame);
    };
    const toggleFullscreen = () => {
        if (!document.fullscreenElement) {
            // è¿›å…¥å…¨å±
            containerRef.current?.requestFullscreen().then(() => {
                setIsFullscreen(true);
            });
        } else {
            // é€€å‡ºå…¨å±
            document.exitFullscreen().then(() => {
                setIsFullscreen(false);
            });
        }
    };

    // ç›‘å¬å…¨å±å˜åŒ–ï¼ˆé˜²æ­¢ç”¨æˆ·æŒ‰ Esc é€€å‡ºæ—¶çŠ¶æ€æ²¡æ›´æ–°ï¼‰
    useEffect(() => {
        const handleChange = () => {
            setIsFullscreen(!!document.fullscreenElement);
        };
        document.addEventListener("fullscreenchange", handleChange);
        return () => document.removeEventListener("fullscreenchange", handleChange);
    }, []);

    // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
    useEffect(() => {
        return () => stopWebcam();
    }, []);

    // --- 5. å¤„ç†æ–‡ä»¶ä¸Šä¼  ---
    const handleImageUpload = (e: React.ChangeEvent<HTMLInputElement>) => {
        const file = e.target.files?.[0];
        if (file) {
            // åœæ­¢æ‘„åƒå¤´
            if (isWebcamOpen) stopWebcam();

            const reader = new FileReader();
            reader.onload = (event) => {
                setImageSrc(event.target?.result as string);
                setInferenceTime(null);
                // æ¸…ç©º Canvas
                if (canvasRef.current) {
                    const ctx = canvasRef.current.getContext("2d");
                    ctx?.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);
                }
            };
            reader.readAsDataURL(file);
        }
    };
    const handleVideoUpload = (event: React.ChangeEvent<HTMLInputElement>) => {
        const file = event.target.files?.[0];
        if (file && videoRef.current) {
            setImageSrc(null);
            setInferenceTime(null); // åŒæ—¶æ¸…ç©ºä¹‹å‰çš„æ¨ç†æ•°æ®
            // 1. è®¾ç½®åŠ è½½çŠ¶æ€ (è®©ç”¨æˆ·çŸ¥é“æˆ‘ä»¬åœ¨å¤„ç†)
            setLoading(true);
            // ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šæœ‰æ–°è§†é¢‘è¿›æ¥ï¼Œå…ˆé”€æ¯æ—§å›¾ç‰‡


            // 2. å…³é—­ä¹‹å‰çš„èµ„æº
            if (isWebcamOpen) stopWebcam();
            // å¦‚æœä¹‹å‰æœ‰ ObjectURLï¼Œæœ€å¥½é‡Šæ”¾æ‰ï¼ˆå¯é€‰ä¼˜åŒ–ï¼‰
            if (videoRef.current.src.startsWith("blob:")) {
                URL.revokeObjectURL(videoRef.current.src);
            }

            // 3. ä½¿ç”¨ createObjectURL (è¿™æ˜¯ç¬é—´å®Œæˆçš„ï¼Œä¸éœ€è¦è¯»å–æ–‡ä»¶å†…å®¹)
            const url = URL.createObjectURL(file);
            videoRef.current.src = url;
            videoRef.current.srcObject = null;

            videoRef.current.loop = true;
            videoRef.current.muted = true;

            // 4. ç›‘å¬ "canplay" äº‹ä»¶ (è¡¨ç¤ºè§†é¢‘å·²ç»ç¼“å†²å¥½ï¼Œå¯ä»¥å¼€å§‹æ’­æ”¾äº†)
            videoRef.current.oncanplay = () => {
                // åªæœ‰å½“è§†é¢‘çœŸçš„å¯ä»¥æ’­äº†ï¼Œæ‰å¼€å§‹
                videoRef.current?.play();
                setIsWebcamOpen(true);
                setLoading(false); // å…³é—­ Loading
                detectFrame();     // å¯åŠ¨ AI

                // æ¸…é™¤ç›‘å¬å™¨ï¼Œé˜²æ­¢å¾ªç¯è§¦å‘
                if (videoRef.current) videoRef.current.oncanplay = null;
            };

            // 5. é”™è¯¯å¤„ç†
            videoRef.current.onerror = () => {
                setLoading(false);
                alert("è§†é¢‘æ ¼å¼ä¸æ”¯æŒæˆ–æ— æ³•åŠ è½½");
            };
        }
    };
    // --- å½“ imageSrc æ”¹å˜æ—¶ï¼Œä»…è°ƒæ•´ Canvas å°ºå¯¸ï¼Œä¸ç»˜åˆ¶å›¾ç‰‡ ---
    useEffect(() => {
        if (imageSrc && canvasRef.current) {
            const img = new Image();
            img.src = imageSrc;
            img.onload = () => {
                const canvas = canvasRef.current!;
                canvas.width = img.width;
                canvas.height = img.height;

                // âš ï¸ åˆ é™¤ç»˜åˆ¶ä»£ç ï¼Œé˜²æ­¢è¦†ç›– img æ ‡ç­¾
                const ctx = canvas.getContext("2d");
                if (ctx) {
                    ctx.clearRect(0, 0, canvas.width, canvas.height);
                }
            };
        }
    }, [imageSrc]);

    return (
        <div className="container mx-auto p-4 max-w-6xl">
            <div className="flex flex-col items-center mb-8 space-y-2">
                <h1 className="text-4xl font-extrabold tracking-tight lg:text-5xl bg-gradient-to-r from-blue-600 to-indigo-600 bg-clip-text text-transparent">
                    YOLO11 Object Detection
                </h1>
                <p className="text-muted-foreground">
                    Next.js + ONNX Runtime Web + WebAssembly
                </p>
            </div>

            <Card className="overflow-hidden border-2 border-slate-100 shadow-xl">
                <CardContent className="p-0">
                    {/* è§†è§‰å±•ç¤ºåŒºåŸŸ */}
                    {/* 1. å¤–å±‚å®¹å™¨ï¼šä½¿ç”¨ Flex å±…ä¸­ï¼ŒèƒŒæ™¯é»‘è‰² */}
                    {/* æ³¨æ„ï¼šå»æ‰äº† min-h-[400px]ï¼Œæ”¹ç”¨ fit-content çš„é€»è¾‘ */}
                    <div
                        ref={containerRef}
                        className={`relative flex justify-center items-center bg-black overflow-hidden rounded-lg border border-slate-800 ${
                            // å…¨å±æ—¶æ’‘æ»¡ï¼Œéå…¨å±æ—¶è‡ªé€‚åº”
                            isFullscreen ? "w-screen h-screen" : "w-full h-auto min-h-[480px]"
                            }`}
                    >

                        {/* 2. å†…å±‚åŒ…è£…å™¨ï¼šä¸‰æ˜æ²»ç»“æ„ï¼Œå†…å®¹æ’‘å¼€å®½é«˜ */}
                        <div className="relative inline-flex max-w-full max-h-full items-center justify-center">

                            {/* A. è§†é¢‘å±‚ï¼šä»…åœ¨ isWebcamOpen ä¸º true æ—¶æ˜¾ç¤º */}
                            <video
                                ref={videoRef}
                                className={`block w-auto h-auto max-w-full ${isFullscreen ? "max-h-screen" : "max-h-[80vh]"
                                    } ${!isWebcamOpen ? "hidden" : ""}`} // å…³é”®ï¼šç”¨ CSS éšè—è€Œä¸æ˜¯é”€æ¯ DOM
                                muted
                                playsInline
                            />

                            {/* B. å›¾ç‰‡å±‚ï¼šä»…åœ¨æœ‰å›¾ç‰‡ä¸”æ‘„åƒå¤´å…³é—­æ—¶æ˜¾ç¤º */}
                            {/* ä¿®å¤æ ¸å¿ƒï¼šè®© img æ ‡ç­¾çœŸå®å­˜åœ¨ï¼Œç”±å®ƒå†³å®šå®½é«˜æ¯” */}
                            {imageSrc && !isWebcamOpen && (
                                <img
                                    src={imageSrc}
                                    alt="Preview"
                                    className={`block w-auto h-auto max-w-full ${isFullscreen ? "max-h-screen" : "max-h-[80vh]"
                                        } object-contain`}
                                    // å›¾ç‰‡åŠ è½½å®Œæˆåï¼ŒåŒæ­¥ Canvas å°ºå¯¸
                                    onLoad={(e) => {
                                        const img = e.currentTarget;
                                        if (canvasRef.current) {
                                            canvasRef.current.width = img.naturalWidth;
                                            canvasRef.current.height = img.naturalHeight;
                                        }
                                    }}
                                />
                            )}

                            {/* C. Canvas å±‚ï¼šç»å¯¹å®šä½è¦†ç›–ï¼ŒèƒŒæ™¯é€æ˜ */}
                            <canvas
                                ref={canvasRef}
                                className="absolute inset-0 w-full h-full pointer-events-none"
                            />
                        </div>

                        {/* Loading é®ç½© (ä»£ç ä¿æŒä¸å˜ï¼Œæ”¾åœ¨æœ€å¤–å±‚ div é‡Œå³å¯) */}
                        {loading && (
                            <div className="absolute inset-0 z-50 flex flex-col items-center justify-center bg-black/50 backdrop-blur-sm">
                                <Loader2 className="h-12 w-12 text-white animate-spin mb-4" />
                                <p className="text-white font-medium">æ­£åœ¨åˆå§‹åŒ– AI...</p>
                            </div>
                        )}

                        {/* å…¨å±æŒ‰é’® (ä»£ç ä¿æŒä¸å˜) */}
                        {isWebcamOpen && (
                            <button
                                onClick={toggleFullscreen}
                                className="absolute top-4 right-4 z-50 p-2 bg-black/50 hover:bg-black/70 text-white rounded-full transition-colors"
                            >
                                {isFullscreen ? <Minimize2 className="h-6 w-6" /> : <Maximize2 className="h-6 w-6" />}
                            </button>
                        )}

                        {/* ç©ºçŠ¶æ€æç¤º (ä»£ç ä¿æŒä¸å˜) */}
                        {!imageSrc && !isWebcamOpen && !loading && (
                            /* ... ä½ çš„ç©ºçŠ¶æ€ä»£ç  ... */
                            <div className="absolute inset-0 flex flex-col items-center justify-center text-slate-500">
                                <p>è¯·ä¸Šä¼ è§†é¢‘æˆ–å¼€å¯æ‘„åƒå¤´</p>
                            </div>
                        )}
                    </div>

                    {/* æ§åˆ¶æ  */}
                    <div className="p-6 bg-white border-t flex flex-col sm:flex-row gap-4 justify-between items-center">

                        {/* çŠ¶æ€æ˜¾ç¤º */}
                        <div className="flex items-center gap-4 text-sm font-medium">
                            <div className={`flex items-center gap-2 ${model ? 'text-green-600' : 'text-orange-500'}`}>
                                <div className={`w-3 h-3 rounded-full ${model ? 'bg-green-500' : 'bg-orange-400 animate-pulse'}`} />
                                {model ? "æ¨¡å‹å·²åŠ è½½" : "åŠ è½½æ¨¡å‹ä¸­..."}
                            </div>
                            {inferenceTime && (
                                <div className="flex items-center gap-2 text-blue-600">
                                    <Zap className="h-4 w-4 fill-current" />
                                    {inferenceTime.toFixed(1)} ms
                                </div>
                            )}
                        </div>

                        {/* æŒ‰é’®ç»„ */}
                        <div className="flex gap-3">
                            <input
                                type="file"
                                id="upload"
                                className="hidden"
                                accept="image/*"
                                ref={fileInputRef}
                                onChange={handleImageUpload}
                            />

                            <Button
                                variant="outline"
                                onClick={() => fileInputRef.current?.click()}
                                disabled={isWebcamOpen}
                            >
                                <Upload className="mr-2 h-4 w-4" />
                                {imageSrc ? "æ¢ä¸€å¼ " : "ä¸Šä¼ å›¾ç‰‡"}
                            </Button>

                            {/* éšè—çš„è§†é¢‘ input */}
                            <input
                                type="file"
                                id="upload-video"
                                className="hidden"
                                accept="video/*"
                                ref={videoInputRef}
                                onChange={handleVideoUpload}
                            />

                            {/* ä¸Šä¼ è§†é¢‘æŒ‰é’® */}
                            <Button
                                variant="outline"
                                onClick={() => videoInputRef.current?.click()}
                                disabled={isWebcamOpen}
                            >
                                <Play className="mr-2 h-4 w-4" />
                                ä¸Šä¼ è§†é¢‘æ£€æµ‹
                            </Button>

                            <Button
                                onClick={runInference}
                                disabled={!model || !imageSrc || loading || isWebcamOpen}
                                className="min-w-[120px]"
                            >
                                {loading ? <Loader2 className="mr-2 h-4 w-4 animate-spin" /> : <Play className="mr-2 h-4 w-4" />}
                                é™æ€æ£€æµ‹
                            </Button>

                            <Button
                                variant={isWebcamOpen ? "destructive" : "default"}
                                onClick={startWebcam} // è¿™é‡Œä¸ç”¨å˜ï¼ŒstartWebcam é‡Œæœ‰ stop é€»è¾‘
                                disabled={!model}
                                className={isWebcamOpen ? "animate-pulse" : ""}
                            >
                                {isWebcamOpen ? (
                                    <StopCircle className="mr-2 h-4 w-4" />
                                ) : (
                                    <Camera className="mr-2 h-4 w-4" />
                                )}

                                {/* --- ä¿®æ”¹è¿™é‡Œçš„æ–‡æ¡ˆé€»è¾‘ --- */}
                                {isWebcamOpen
                                    ? (videoRef.current?.srcObject ? "å…³é—­æ‘„åƒå¤´" : "åœæ­¢è§†é¢‘")
                                    : "å¼€å¯æ‘„åƒå¤´"
                                }
                            </Button>
                        </div>
                    </div>
                </CardContent>
            </Card>

            {/* Footer Info */}
            <div className="mt-8 grid grid-cols-1 md:grid-cols-3 gap-6 text-center">
                <div className="p-4 rounded-lg bg-slate-50">
                    <h3 className="font-bold text-slate-800">100% æœ¬åœ°éšç§</h3>
                    <p className="text-sm text-slate-500 mt-1">ä½ çš„å›¾ç‰‡å’Œè§†é¢‘æµå®Œå…¨åœ¨æµè§ˆå™¨å†…å¤„ç†ï¼Œä¸ä¼šä¸Šä¼ åˆ°æœåŠ¡å™¨ã€‚</p>
                </div>
                <div className="p-4 rounded-lg bg-slate-50">
                    <h3 className="font-bold text-slate-800">YOLO11s åŠ æŒ</h3>
                    <p className="text-sm text-slate-500 mt-1">ä½¿ç”¨æœ€æ–° SOTA æ¨¡å‹ï¼Œå¹³è¡¡é€Ÿåº¦ä¸ç²¾åº¦ã€‚</p>
                </div>
                <div className="p-4 rounded-lg bg-slate-50">
                    <h3 className="font-bold text-slate-800">WebAssembly</h3>
                    <p className="text-sm text-slate-500 mt-1">é€šè¿‡ ONNX Runtime å®ç°æ¥è¿‘åŸç”Ÿçš„æ¨ç†é€Ÿåº¦ã€‚</p>
                </div>
            </div>
        </div>
    );
}