"use client";

import { useState, useRef, useEffect } from "react";
import * as ort from "onnxruntime-web";
import { Button } from "@/components/ui/button";
import { Card, CardContent } from "@/components/ui/card";
import { preprocess, renderBoxes } from "@/lib/utils";
import {
    Camera, StopCircle, Play, Loader2,
    Maximize2, Minimize2,
    Zap, Upload
} from "lucide-react";

// --- 1. å…¨å±€é…ç½® ONNX Runtime ---
ort.env.wasm.wasmPaths = "/";
// @ts-ignore
ort.env.wasm.numThreads = 1;

export default function DemoPage() {
    // --- çŠ¶æ€ç®¡ç† ---
    const [model, setModel] = useState<ort.InferenceSession | null>(null);
    const [imageSrc, setImageSrc] = useState<string | null>(null);
    const [loading, setLoading] = useState(false);
    const [inferenceTime, setInferenceTime] = useState<number | null>(null);
    const [isWebcamOpen, setIsWebcamOpen] = useState(false);

    // --- Refs ---
    const canvasRef = useRef<HTMLCanvasElement>(null);
    const videoRef = useRef<HTMLVideoElement>(null);
    const requestRef = useRef<number>(0);
    const fileInputRef = useRef<HTMLInputElement>(null);
    const videoInputRef = useRef<HTMLInputElement>(null);
    const isProcessingRef = useRef(false);
    const lastTimeRef = useRef(0);
    const frameCountRef = useRef(0);
    const containerRef = useRef<HTMLDivElement>(null);
    const [isFullscreen, setIsFullscreen] = useState(false);
    

    // --- 2. åˆå§‹åŒ–åŠ è½½æ¨¡å‹ ---
    useEffect(() => {
        const initModel = async () => {
            try {
                const modelPath = "/model/yolo11n.onnx";
                const session = await ort.InferenceSession.create(modelPath, {
                    executionProviders: ["wasm"],
                });
                setModel(session);
                console.log("æ¨¡å‹åŠ è½½æˆåŠŸ!");
            } catch (e) {
                console.error("æ¨¡å‹åŠ è½½å¤±è´¥:", e);
                alert("æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ public/model ç›®å½•");
            }
        };
        initModel();
    }, []);

    // --- 3. é™æ€å›¾ç‰‡æ¨ç†é€»è¾‘ ---
    const runInference = async () => {
        if (!model || !imageSrc || !canvasRef.current) return;
        if (isWebcamOpen) stopWebcam();

        setLoading(true);
        const start = performance.now();

        try {
            const img = new Image();
            img.src = imageSrc;
            await new Promise((resolve) => (img.onload = resolve));

            const canvas = canvasRef.current;
            const ctx = canvas.getContext("2d");

            canvas.width = img.naturalWidth;
            canvas.height = img.naturalHeight;

            ctx?.clearRect(0, 0, canvas.width, canvas.height);

            const inputTensorData = await preprocess(img, 640, 640);
            const inputTensor = new ort.Tensor("float32", Float32Array.from(inputTensorData), [1, 3, 640, 640]);

            const outputs = await model.run({ images: inputTensor });
            const output = outputs["output0"];

            const end = performance.now();
            setInferenceTime(end - start);

            renderBoxes(canvas, 0.25, output.data as Float32Array, 0, 0);

        } catch (e) {
            console.error(e);
            alert("æ¨ç†å‡ºé”™");
        } finally {
            setLoading(false);
        }
    };

    // --- 4. æ‘„åƒå¤´å¤„ç†é€»è¾‘ ---
    const startWebcam = async () => {
        if (isWebcamOpen) {
            stopWebcam();
            return;
        }

        setImageSrc(null);
        setInferenceTime(null);

        try {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: {
                    // ğŸ”¥ ç§»åŠ¨ç«¯æ ¸å¿ƒï¼šä¼˜å…ˆä½¿ç”¨åç½®æ‘„åƒå¤´
                    facingMode: "environment",
                    width: { ideal: 640 },
                    height: { ideal: 480 }
                },
                audio: false,
            });

            if (videoRef.current) {
                videoRef.current.srcObject = stream;
                videoRef.current.onloadedmetadata = () => {
                    videoRef.current?.play();
                    setIsWebcamOpen(true);
                    detectFrame();
                };
            }
        } catch (err) {
            console.error("æ‘„åƒå¤´å¯åŠ¨å¤±è´¥:", err);
            alert("æ— æ³•è®¿é—®æ‘„åƒå¤´ï¼Œè¯·ç¡®è®¤å·²æˆäºˆæƒé™ä¸”åœ¨ HTTPS ç¯å¢ƒä¸‹è¿è¡Œã€‚");
        }
    };

    const stopWebcam = () => {
        if (requestRef.current) {
            cancelAnimationFrame(requestRef.current);
            requestRef.current = undefined;
        }

        if (videoRef.current) {
            const video = videoRef.current;
            video.onerror = null;
            video.onloadeddata = null;

            if (video.srcObject) {
                const stream = video.srcObject as MediaStream;
                stream.getTracks().forEach(track => track.stop());
                video.srcObject = null;
            } else {
                video.pause();
                video.src = "";
                video.load();
            }
        }

        if (canvasRef.current) {
            const ctx = canvasRef.current.getContext("2d");
            ctx?.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);
        }

        setIsWebcamOpen(false);
        setLoading(false);

        if (document.fullscreenElement) {
            document.exitFullscreen().catch(() => { });
        }
    };

    // --- æ£€æµ‹å¾ªç¯ ---
    const detectFrame = async () => {
        if (!videoRef.current || !canvasRef.current || !model) return;

        const video = videoRef.current;
        const canvas = canvasRef.current;
        const ctx = canvas.getContext("2d");

        if (video.readyState === 4 && !video.paused && !video.ended) {
            // å°ºå¯¸åŒæ­¥ï¼šCanvas åˆ†è¾¨ç‡å¿…é¡»ç­‰äºè§†é¢‘åŸå§‹åˆ†è¾¨ç‡
            if (canvas.width !== video.videoWidth || canvas.height !== video.videoHeight) {
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
            }

            const now = Date.now();
            if (now - lastTimeRef.current >= 30 && !isProcessingRef.current) {
                isProcessingRef.current = true;
                lastTimeRef.current = now;

                try {
                    const start = performance.now();

                    const inputTensorData = await preprocess(video, 640, 640);
                    const inputTensor = new ort.Tensor("float32", Float32Array.from(inputTensorData), [1, 3, 640, 640]);
                    const outputs = await model.run({ images: inputTensor });
                    const output = outputs["output0"];

                    const end = performance.now();

                    frameCountRef.current++;
                    if (frameCountRef.current % 5 === 0) {
                        setInferenceTime(end - start);
                    }

                    ctx?.clearRect(0, 0, canvas.width, canvas.height);
                    renderBoxes(canvas, 0.25, output.data as Float32Array, 0, 0);

                } catch (e) {
                    console.error("æ¨ç†æŠ¥é”™:", e);
                } finally {
                    isProcessingRef.current = false;
                }
            }
        }
        requestRef.current = requestAnimationFrame(detectFrame);
    };

    const toggleFullscreen = () => {
        if (!document.fullscreenElement) {
            containerRef.current?.requestFullscreen().then(() => setIsFullscreen(true));
        } else {
            document.exitFullscreen().then(() => setIsFullscreen(false));
        }
    };

    useEffect(() => {
        const handleChange = () => setIsFullscreen(!!document.fullscreenElement);
        document.addEventListener("fullscreenchange", handleChange);
        return () => document.removeEventListener("fullscreenchange", handleChange);
    }, []);

    useEffect(() => {
        return () => stopWebcam();
    }, []);

    // --- æ–‡ä»¶ä¸Šä¼ å¤„ç† ---
    const handleImageUpload = (e: React.ChangeEvent<HTMLInputElement>) => {
        const file = e.target.files?.[0];
        if (file) {
            if (isWebcamOpen) stopWebcam();
            const reader = new FileReader();
            reader.onload = (event) => {
                setImageSrc(event.target?.result as string);
                setInferenceTime(null);
                if (canvasRef.current) {
                    const ctx = canvasRef.current.getContext("2d");
                    ctx?.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);
                }
            };
            reader.readAsDataURL(file);
        }
        // ğŸ”¥ åŠ ä¸Šè¿™è¡Œ
        e.target.value = "";
    };

    const handleVideoUpload = (event: React.ChangeEvent<HTMLInputElement>) => {
        const file = event.target.files?.[0];

        // âš ï¸ å…³é”®ä¿®å¤ 1: å¦‚æœæ²¡æœ‰æ–‡ä»¶ç›´æ¥è¿”å›ï¼Œé˜²æ­¢æŠ¥é”™
        if (!file || !videoRef.current) return;

        // 1. ç«‹å³æ¸…ç©ºä¹‹å‰çš„çŠ¶æ€
        setImageSrc(null);
        setInferenceTime(null);
        setLoading(true);

        // 2. å¦‚æœå½“å‰æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡ï¼Œå…ˆå¼ºåˆ¶åœæ­¢
        // æ³¨æ„ï¼šè¿™é‡Œæ‰‹åŠ¨æ‰§è¡Œ stopWebcam çš„éƒ¨åˆ†é€»è¾‘ï¼Œé¿å…ç›´æ¥è°ƒç”¨ stopWebcam() å¯èƒ½å¸¦æ¥çš„çŠ¶æ€å†²çª
        if (requestRef.current) {
            cancelAnimationFrame(requestRef.current);
            requestRef.current = undefined;
        }

        // é‡Šæ”¾æ—§çš„ Blob URL å†…å­˜
        if (videoRef.current.src.startsWith("blob:")) {
            URL.revokeObjectURL(videoRef.current.src);
        }

        // 3. åŠ è½½æ–°è§†é¢‘
        const url = URL.createObjectURL(file);
        videoRef.current.src = url;
        videoRef.current.srcObject = null;
        videoRef.current.loop = true;
        videoRef.current.muted = true;

        // 4. ç›‘å¬è§†é¢‘å‡†å¤‡å°±ç»ª
        videoRef.current.oncanplay = () => {
            if (!videoRef.current) return;

            videoRef.current.play();
            setIsWebcamOpen(true); // æ‰“å¼€æ˜¾ç¤ºå¼€å…³
            setLoading(false);     // å…³é—­ Loading
            detectFrame();         // å¯åŠ¨ AI å¾ªç¯

            // é˜²æ­¢é‡å¤è§¦å‘
            videoRef.current.oncanplay = null;
        };

        videoRef.current.onerror = () => {
            setLoading(false);
            alert("è§†é¢‘æ— æ³•åŠ è½½æˆ–æ ¼å¼ä¸æ”¯æŒ");
        };

        // ğŸ”¥ å…³é”®ä¿®å¤ 2: æ— è®ºæˆåŠŸå¤±è´¥ï¼Œæœ€åéƒ½è¦æ¸…ç©º input çš„å€¼
        // è¿™æ ·ä¸‹æ¬¡é€‰åŒä¸€ä¸ªæ–‡ä»¶æ—¶ï¼ŒonChange æ‰ä¼šå†æ¬¡è§¦å‘
        event.target.value = "";
    };

    // imageSrc æ”¹å˜æ—¶é‡ç½® Canvas
    useEffect(() => {
        if (imageSrc && canvasRef.current) {
            const img = new Image();
            img.src = imageSrc;
            img.onload = () => {
                const canvas = canvasRef.current!;
                canvas.width = img.width;
                canvas.height = img.height;
                const ctx = canvas.getContext("2d");
                ctx?.clearRect(0, 0, canvas.width, canvas.height);
            };
        }
    }, [imageSrc]);

    return (
        // ğŸ”¥ ä¿®æ”¹1: å®¹å™¨ padding åœ¨æ‰‹æœºä¸Šå˜å° (p-2)ï¼ŒPC ä¸Šä¿æŒ (p-4)
        <div className="container mx-auto p-2 md:p-4 max-w-6xl">
            <div className="flex flex-col items-center mb-6 space-y-2">
                {/* ğŸ”¥ ä¿®æ”¹2: æ ‡é¢˜å­—ä½“åœ¨æ‰‹æœºä¸Šå˜å°ï¼Œé˜²æ­¢æ¢è¡Œå°´å°¬ */}
                <h1 className="text-2xl md:text-5xl font-extrabold tracking-tight bg-gradient-to-r from-blue-600 to-indigo-600 bg-clip-text text-transparent text-center">
                    YOLO11 Object Detection
                </h1>
                <p className="text-xs md:text-base text-muted-foreground text-center">
                    Next.js + ONNX Runtime Web + WebAssembly
                </p>
            </div>

            <Card className="overflow-hidden border-2 border-slate-100 shadow-xl">
                <CardContent className="p-0">
                    {/* è§†è§‰å±•ç¤ºåŒºåŸŸ */}
                    <div
                        ref={containerRef}
                        // ğŸ”¥ ä¿®æ”¹3: 
                        // - åªæœ‰å…¨å±æ—¶æ‰ h-screen
                        // - æ™®é€šæ¨¡å¼ä¸‹ï¼Œå»æ‰ min-h-[480px]ï¼Œæ”¹ä¸º aspect-video (16:9) æˆ– min-h-[50vh]
                        // - è¿™æ ·æ‰‹æœºç«–å±æ—¶ï¼Œè§†é¢‘åŒºåŸŸä¸ä¼šå¤ªé«˜å¯¼è‡´çœ‹ä¸åˆ°ä¸‹é¢çš„æŒ‰é’®
                        className={`relative flex justify-center items-center bg-black overflow-hidden ${isFullscreen ? "w-screen h-screen fixed inset-0 z-50 rounded-none" : "w-full min-h-[50vh] md:min-h-[480px] rounded-lg"
                            }`}
                    >
                        {/* åŒ…è£…å™¨ï¼šç¡®ä¿è§†é¢‘åœ¨æ‰‹æœºä¸Šä¸è¶…è¿‡å±å¹•å®½åº¦ */}
                        <div className="relative inline-flex max-w-full max-h-full items-center justify-center">

                            <video
                                ref={videoRef}
                                // ğŸ”¥ ä¿®æ”¹4: w-full ç¡®ä¿è§†é¢‘å®½åº¦è‡ªé€‚åº”å®¹å™¨ï¼Œh-auto ä¿æŒæ¯”ä¾‹
                                className={`block w-full h-auto max-w-full ${isFullscreen ? "max-h-screen" : "max-h-[80vh]"} ${!isWebcamOpen ? "hidden" : ""}`}
                                muted
                                playsInline
                            />

                            {imageSrc && !isWebcamOpen && (
                                <img
                                    src={imageSrc}
                                    alt="Preview"
                                    className={`block w-full h-auto max-w-full ${isFullscreen ? "max-h-screen" : "max-h-[80vh]"} object-contain`}
                                    onLoad={(e) => {
                                        const img = e.currentTarget;
                                        if (canvasRef.current) {
                                            canvasRef.current.width = img.naturalWidth;
                                            canvasRef.current.height = img.naturalHeight;
                                        }
                                    }}
                                />
                            )}

                            <canvas
                                ref={canvasRef}
                                className="absolute inset-0 w-full h-full pointer-events-none"
                            />
                        </div>

                        {loading && (
                            <div className="absolute inset-0 z-50 flex flex-col items-center justify-center bg-black/50 backdrop-blur-sm">
                                <Loader2 className="h-12 w-12 text-white animate-spin mb-4" />
                                <p className="text-white font-medium">Loading AI...</p>
                            </div>
                        )}

                        {isWebcamOpen && (
                            <button
                                onClick={toggleFullscreen}
                                className="absolute top-4 right-4 z-50 p-2 bg-black/50 hover:bg-black/70 text-white rounded-full transition-colors"
                            >
                                {isFullscreen ? <Minimize2 className="h-6 w-6" /> : <Maximize2 className="h-6 w-6" />}
                            </button>
                        )}

                        {!imageSrc && !isWebcamOpen && !loading && (
                            <div className="absolute inset-0 flex flex-col items-center justify-center text-slate-500 gap-2">
                                <Camera className="w-12 h-12 opacity-50" />
                                <p className="text-sm">ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹æ£€æµ‹</p>
                            </div>
                        )}
                    </div>

                    {/* æ§åˆ¶æ  */}
                    {/* ğŸ”¥ ä¿®æ”¹5: 
              - flex-col: æ‰‹æœºä¸Šå‚ç›´æ’åˆ—
              - sm:flex-row: å¹³æ¿/ç”µè„‘ä¸Šæ°´å¹³æ’åˆ—
          */}
                    <div className="p-4 bg-white border-t flex flex-col sm:flex-row gap-4 justify-between items-center">

                        <div className="flex items-center gap-4 text-sm font-medium w-full sm:w-auto justify-between sm:justify-start">
                            <div className={`flex items-center gap-2 ${model ? 'text-green-600' : 'text-orange-500'}`}>
                                <div className={`w-2 h-2 md:w-3 md:h-3 rounded-full ${model ? 'bg-green-500' : 'bg-orange-400 animate-pulse'}`} />
                                {model ? "Ready" : "Loading..."}
                            </div>
                            {inferenceTime && (
                                <div className="flex items-center gap-2 text-blue-600">
                                    <Zap className="h-4 w-4 fill-current" />
                                    {inferenceTime.toFixed(0)}ms
                                </div>
                            )}
                        </div>

                        {/* æŒ‰é’®åŒºåŸŸï¼šæ‰‹æœºä¸Šå®½åº¦å æ»¡ (w-full)ï¼ŒæŒ‰é’®å¹³åˆ† (grid-cols-2) */}
                        <div className="grid grid-cols-2 sm:flex gap-2 w-full sm:w-auto">
                            <input
                                type="file"
                                className="hidden"
                                accept="image/*"
                                ref={fileInputRef}
                                onChange={handleImageUpload}
                            />
                            <Button
                                variant="outline"
                                onClick={() => fileInputRef.current?.click()}
                                disabled={isWebcamOpen}
                                className="w-full sm:w-auto"
                            >
                                <Upload className="mr-2 h-4 w-4" />
                                å›¾ç‰‡
                            </Button>

                            <input
                                type="file"
                                className="hidden"
                                accept="video/*"
                                ref={videoInputRef}
                                onChange={handleVideoUpload}
                            />
                            <Button
                                variant="outline"
                                onClick={() => videoInputRef.current?.click()}
                                disabled={isWebcamOpen}
                                className="w-full sm:w-auto"
                            >
                                <Play className="mr-2 h-4 w-4" />
                                è§†é¢‘
                            </Button>

                            <Button
                                onClick={runInference}
                                disabled={!model || !imageSrc || loading || isWebcamOpen}
                                className="w-full sm:w-auto col-span-2 sm:col-span-1"
                            >
                                é™æ€æ£€æµ‹
                            </Button>

                            <Button
                                variant={isWebcamOpen ? "destructive" : "default"}
                                onClick={startWebcam}
                                disabled={!model}
                                className={`w-full sm:w-auto col-span-2 sm:col-span-1 ${isWebcamOpen ? "animate-pulse" : ""}`}
                            >
                                {isWebcamOpen ? <StopCircle className="mr-2 h-4 w-4" /> : <Camera className="mr-2 h-4 w-4" />}
                                {isWebcamOpen ? "åœæ­¢" : "æ‘„åƒå¤´"}
                            </Button>
                        </div>
                    </div>
                </CardContent>
            </Card>

            {/* åº•éƒ¨ä¿¡æ¯ï¼Œæ‰‹æœºä¸Šéšè—æˆ–ç¼©å° */}
            <div className="mt-8 hidden md:grid grid-cols-3 gap-6 text-center">
                {/* ... ä¿æŒåŸæ · ... */}
                <div className="p-4 rounded-lg bg-slate-50">
                    <h3 className="font-bold text-slate-800">100% æœ¬åœ°éšç§</h3>
                    <p className="text-sm text-slate-500 mt-1">ä½ çš„å›¾ç‰‡å’Œè§†é¢‘æµå®Œå…¨åœ¨æµè§ˆå™¨å†…å¤„ç†ã€‚</p>
                </div>
                <div className="p-4 rounded-lg bg-slate-50">
                    <h3 className="font-bold text-slate-800">YOLO11s</h3>
                    <p className="text-sm text-slate-500 mt-1">SOTA å®æ—¶ç›®æ ‡æ£€æµ‹ã€‚</p>
                </div>
                <div className="p-4 rounded-lg bg-slate-50">
                    <h3 className="font-bold text-slate-800">WebAssembly</h3>
                    <p className="text-sm text-slate-500 mt-1">ONNX Runtime åŸç”Ÿé€Ÿåº¦ã€‚</p>
                </div>
            </div>
        </div>
    );
}